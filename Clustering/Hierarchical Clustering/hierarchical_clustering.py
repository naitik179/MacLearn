# -*- coding: utf-8 -*-
"""hierarchical Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vC115oCFb4JBXO0oNaIJFTkhwFwjlTKe

## Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

dataset = pd.read_csv('Mall_Customers.csv')
dataset

"""## Getting the dataset ready"""

X = dataset.iloc[: , [3,4]].values
X

"""## Using Dendogram tofind the optimum number of Clusters"""

import scipy.cluster.hierarchy as sch
dendrogram = sch.dendrogram(sch.linkage(X , method = 'ward'))
plt.title('Dendrogram')
plt.xlabel('Customers')
plt.ylabel('Euclidean Distances')
plt.show()

"""### Optimal no of clusters is equal to 5"""

from sklearn.cluster import AgglomerativeClustering
hc = AgglomerativeClustering(n_clusters =5 , affinity ='euclidean' , linkage = 'ward')
y_hc = hc.fit_predict(X)
y_hc

"""## Visualizing the Clusters"""

plt.scatter(X[y_hc==0 , 0], X[y_hc ==0 , 1] , s = 75 ,c ='red' , label = 'Careful')
plt.scatter(X[y_hc==1 , 0], X[y_hc ==1 , 1] , s = 75 ,c ='blue' , label = 'Careless')
plt.scatter(X[y_hc==2 , 0], X[y_hc ==2 , 1] , s = 75 ,c ='green' , label = 'Targets')
plt.scatter(X[y_hc==3 , 0], X[y_hc ==3 , 1] , s = 75 ,c ='yellow' , label = 'Sensible')
plt.scatter(X[y_hc==4 , 0], X[y_hc ==4 , 1] , s = 75 ,c ='orange' , label = 'Standard')
plt.title('Clusyers of Clients')
plt.xlabel('Annual Income')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()